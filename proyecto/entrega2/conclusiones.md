Conclusiones:

- ¿Cómo mejoró el desarrollo del proyecto al utilizar herramientas de *tracking* y despliegue?
El tracking con MLflow y la automatización del despliegue hicieron el desarrollo más seguro y rápido. Cada experimento guardó hiperparámetros, métricas y artefactos, así sabíamos qué cambios funcionaban sin perder reproducibilidad. Además, al integrar el pipeline con el backend y los contenedores, el mismo modelo registrado en MLflow se reutilizó para predecir en los servicios, reduciendo pasos manuales y evitando inconsistencias entre lo que entrenamos y lo que se publica. Además, el uso de Airflow fue muy beneficioso para encontrar problemas en el código, ya que los logs ayudaban a ver por qué algo arrojaba error o se saltaba algo, de manera que resolverlo era mucho más directo.

- ¿Qué aspectos del despliegue con `Gradio/FastAPI` fueron más desafiantes o interesantes?
Lo más desafiante fue mantener el contrato entre el backend FastAPI y la interfaz Gradio: el pipeline genera features complejos, así que hubo que validar entradas, serializar correctamente las predicciones y propagar errores manejables a la UI. También resultó interesante empaquetar ambos servicios en contenedores separados y coordinarlos por Docker Compose; esa separación permitió iterar la interfaz sin tocar el motor de predicciones y probar todo el flujo end-to-end con datos reales antes de subirlo.

- ¿Cómo aporta `Airflow` a la robustez y escalabilidad del pipeline?
Airflow actúa como orquestador que garantiza robustez y escalabilidad: los sensores aseguran que el pipeline sólo arranque cuando existen nuevos datos, cada etapa (ingesta, limpieza, enriquecimiento, drift, entrenamiento y predicción) corre como tarea independiente con reintentos automáticos, y el branching decide cuándo reentrenar según drift o reglas periódicas. Gracias a los DAGs podemos ejecutar el flujo diario, paralelizar runs, auditar logs históricos y reanudar desde cualquier paso sin intervención manual, lo que hace que el pipeline escale y sea resiliente frente a fallos puntuales.

- ¿Qué se podría mejorar en una versión futura del flujo? ¿Qué partes automatizarían más, qué monitorearían o qué métricas agregarían?
Automatizaría más el ciclo de promoción a producción (p.ej. pipeline CI/CD que ejecute tests, genere imágenes y despliegue con approve manual), añadiría monitoreo continuo del servicio (latencia, throughput, health checks) y métricas de negocio como lift por segmento o cobertura de clientes para detectar degradaciones reales. También instrumentaría el pipeline con alertas cuando el drift supere umbrales o cuando el F1/ROC-AUC caigan respecto al baseline, y ampliaría los tests automatizados (unitarios para transformaciones, de integración para backend/frontend) para reducir regresiones antes de cada release.
